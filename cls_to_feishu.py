# coding=utf-8

import json
import time
import random
from datetime import datetime, timedelta
import os
import sys
from pathlib import Path

import requests
import pytz

# é…ç½®å¸¸é‡
CONFIG = {
    "OUTPUT_DIR": "./output/è´¢è”ç¤¾ç”µæŠ¥",  # è¾“å‡ºç›®å½•
    "FEISHU_WEBHOOK_URL": os.getenv("FEISHU_WEBHOOK_URL", ""),  # é£ä¹¦è‡ªåŠ¨åŒ– Webhook URL
    "MAX_TELEGRAMS": 50,  # æœ€å¤§è·å–ç”µæŠ¥æ•°é‡
    "RED_KEYWORDS": ["åˆ©å¥½", "åˆ©ç©º", "é‡è¦", "çªå‘", "ç´§æ€¥", "å…³æ³¨", "æé†’"],  # æ ‡çº¢å…³é”®è¯
    "FILE_SEPARATOR": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",  # æ–‡ä»¶å†…å®¹åˆ†å‰²çº¿
    # ä»ç¯å¢ƒå˜é‡è¯»å– USE_PROXYï¼Œå¦‚æœæœªè®¾ç½®ï¼Œé»˜è®¤ä¸º False
    "USE_PROXY": os.getenv("USE_PROXY", "False").lower() == "true",
    # ä»ç¯å¢ƒå˜é‡è¯»å– DEFAULT_PROXYï¼Œå¦‚æœæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
    "DEFAULT_PROXY": os.getenv("DEFAULT_PROXY", "http://127.0.0.1:10086"),
}


class TimeHelper:
    """æ—¶é—´å¤„ç†å·¥å…·"""

    @staticmethod
    def get_beijing_time() -> datetime:
        """è·å–åŒ—äº¬æ—¶é—´"""
        return datetime.now(pytz.timezone("Asia/Shanghai"))

    @staticmethod
    def format_date() -> str:
        """è¿”å›æ—¥æœŸæ ¼å¼"""
        return TimeHelper.get_beijing_time().strftime("%Yå¹´%mæœˆ%dæ—¥")

    @staticmethod
    def format_time() -> str:
        """è¿”å›æ—¶é—´æ ¼å¼"""
        return TimeHelper.get_beijing_time().strftime("%H:%M:%S")

    @staticmethod
    def format_datetime() -> str:
        """è¿”å›æ—¥æœŸæ—¶é—´æ ¼å¼"""
        return TimeHelper.get_beijing_time().strftime("%Y-%m-%d %H:%M:%S")




import hashlib
import urllib.parse

class CailianpressAPI:
    """è´¢è”ç¤¾API"""

    @staticmethod
    def _md5(text):
        return hashlib.md5(text.encode('utf-8')).hexdigest()

    @staticmethod
    def _sha1(text):
        return hashlib.sha1(text.encode('utf-8')).hexdigest()

    @staticmethod
    def _get_cls_params(more_params=None):
        if more_params is None:
            more_params = {}
        static_params = {
            "app_name": "CailianpressWeb",
            "os": "web",
            "sv": "7.7.5",
        }
        all_params = {**static_params, **more_params}
        
        # å‚æ•°æ’åºå¯¹äºç­¾åå¾ˆé‡è¦
        sorted_keys = sorted(all_params.keys())
        params_list = []
        for key in sorted_keys:
            params_list.append(f"{key}={all_params[key]}")
        params_string = "&".join(params_list)
        
        signature = CailianpressAPI._md5(CailianpressAPI._sha1(params_string))
        all_params["sign"] = signature
        return all_params

    @staticmethod
    def fetch_telegrams(max_count=CONFIG["MAX_TELEGRAMS"]):
        """è·å–è´¢è”ç¤¾ç”µæŠ¥"""
        try:
            api_url = "https://www.cls.cn/nodeapi/updateTelegraphList"
            
            params = CailianpressAPI._get_cls_params()
            full_url = f"{api_url}?{urllib.parse.urlencode(params)}"
            
            proxies = None
            if CONFIG["USE_PROXY"]:
                proxies = {"http": CONFIG["DEFAULT_PROXY"], "https": CONFIG["DEFAULT_PROXY"]}

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "keep-alive",
                "Cache-Control": "no-cache",
            }

            print(f"è¯·æ±‚è´¢è”ç¤¾API: {full_url}")
            response = requests.get(full_url, proxies=proxies, headers=headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if data.get("error") == 0 and data.get("data") and data["data"].get("roll_data"):
                telegrams = data["data"]["roll_data"]
                print(f"æˆåŠŸè·å– {len(telegrams)} æ¡è´¢è”ç¤¾ç”µæŠ¥")
                
                processed_telegrams = []
                for item in telegrams:
                    if item.get("is_ad"): # è¿‡æ»¤å¹¿å‘Š
                        continue
                    
                    title = item.get("title", "")
                    content = item.get("brief", "") or title # ä¼˜å…ˆä½¿ç”¨briefï¼Œæ²¡æœ‰åˆ™ç”¨title
                    item_id = item.get("id")
                    url = f"https://www.cls.cn/detail/{item_id}" if item_id else ""
                    
                    timestamp = item.get("ctime")
                    if timestamp:
                        try:
                            timestamp = int(timestamp)
                            item_time = datetime.fromtimestamp(timestamp, pytz.timezone("Asia/Shanghai")).strftime("%H:%M")
                        except (ValueError, TypeError):
                            item_time = ""
                    else:
                        item_time = ""

                    is_red = any(keyword in (title + content) for keyword in CONFIG["RED_KEYWORDS"])

                    processed_telegrams.append({
                        "id": item_id,
                        "title": title,
                        "content": content,
                        "time": item_time,
                        "url": url,
                        "is_red": is_red,
                        "timestamp_raw": timestamp # æ·»åŠ åŸå§‹æ—¶é—´æˆ³
                    })
                
                print(f"å¤„ç†åçš„ç”µæŠ¥æ•°é‡: {len(processed_telegrams)}")
                return processed_telegrams
            else:
                print(f"APIè¿”å›æ ¼å¼é”™è¯¯æˆ–æ— æ•°æ®: {data}")
                return []
        except Exception as e:
            print(f"è·å–è´¢è”ç¤¾ç”µæŠ¥å¤±è´¥: {e}")
            return []


class FileWriter:
    """æ–‡ä»¶å†™å…¥å·¥å…·"""

    @staticmethod
    def save_telegrams_to_file(telegrams):
        """å°†ç”µæŠ¥å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶ï¼Œå¹¶æŒ‰æ—¥æœŸå½’æ¡£å’Œæ’åº"""
        output_dir = Path(CONFIG["OUTPUT_DIR"])
        output_dir.mkdir(parents=True, exist_ok=True)

        # æŒ‰æ—¥æœŸåˆ†ç»„ç”µæŠ¥
        telegrams_by_date = {}
        for t in telegrams:
            if "timestamp_raw" in t and t["timestamp_raw"]:
                try:
                    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸ
                    item_datetime = datetime.fromtimestamp(int(t["timestamp_raw"]), pytz.timezone("Asia/Shanghai"))
                    item_date_str = item_datetime.strftime("%Y-%m-%d")
                    if item_date_str not in telegrams_by_date:
                        telegrams_by_date[item_date_str] = []
                    telegrams_by_date[item_date_str].append(t)
                except (ValueError, TypeError):
                    print(f"è­¦å‘Š: æ— æ³•è§£æç”µæŠ¥æ—¶é—´æˆ³ {t.get('timestamp_raw')}ï¼Œè·³è¿‡æ­¤ç”µæŠ¥çš„æ—¥æœŸå½’æ¡£ã€‚")
                    continue
            else:
                print(f"è­¦å‘Š: ç”µæŠ¥ç¼ºå°‘åŸå§‹æ—¶é—´æˆ³ï¼Œè·³è¿‡æ­¤ç”µæŠ¥çš„æ—¥æœŸå½’æ¡£ã€‚ç”µæŠ¥ID: {t.get('id')}")
                continue

        saved_any_new = False
        for date_str, daily_telegrams in telegrams_by_date.items():
            file_path = output_dir / f"è´¢è”ç¤¾ç”µæŠ¥_{date_str}.md"
            existing_ids = FileWriter._get_existing_telegram_ids(file_path)

            # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„ç”µæŠ¥
            new_telegrams_for_day = [t for t in daily_telegrams if str(t.get("id")) not in existing_ids]

            if not new_telegrams_for_day:
                print(f"æ—¥æœŸ {date_str} æ²¡æœ‰æ–°çš„è´¢è”ç¤¾ç”µæŠ¥éœ€è¦ä¿å­˜ã€‚")
                continue

            # å¯¹æ–°ç”µæŠ¥æŒ‰åŸå§‹æ—¶é—´æˆ³å€’åºæ’åº
            new_telegrams_for_day.sort(key=lambda x: int(x.get("timestamp_raw", 0)), reverse=True)

            # åˆå¹¶æ–°ç”µæŠ¥å’Œæ—§ç”µæŠ¥ï¼Œå¹¶å»é‡
            all_telegrams_for_day = new_telegrams_for_day
            if file_path.exists():
                existing_telegrams = FileWriter._parse_existing_telegrams(file_path)
                all_telegrams_for_day.extend(existing_telegrams)
                # æ ¹æ®IDå»é‡
                seen_ids = set()
                unique_telegrams = []
                for t in all_telegrams_for_day:
                    if str(t.get("id")) not in seen_ids:
                        unique_telegrams.append(t)
                        seen_ids.add(str(t.get("id")))
                all_telegrams_for_day = unique_telegrams

            # å¯¹æ‰€æœ‰ç”µæŠ¥æŒ‰åŸå§‹æ—¶é—´æˆ³å€’åºæ’åº
            all_telegrams_for_day.sort(key=lambda x: int(x.get("timestamp_raw", 0)), reverse=True)

            # æ„å»ºæ–‡ä»¶å†…å®¹
            content = FileWriter._build_file_content(date_str, all_telegrams_for_day)
            if not content:
                continue
            
            try:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)
                print(f"æ—¥æœŸ {date_str} çš„è´¢è”ç¤¾ç”µæŠ¥å·²ä¿å­˜åˆ°: {file_path}")
                saved_any_new = True
            except Exception as e:
                print(f"ä¿å­˜æ—¥æœŸ {date_str} çš„ç”µæŠ¥åˆ°æ–‡ä»¶å¤±è´¥: {e}")
        
        return saved_any_new

    @staticmethod
    def _get_existing_telegram_ids(file_path):
        """ä»æ–‡ä»¶ä¸­è¯»å–å·²å­˜åœ¨çš„ç”µæŠ¥ID"""
        existing_ids = set()
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                import re
                # åŒ¹é…ä¸¤ç§URLæ ¼å¼ï¼Œç¡®ä¿èƒ½æå–ID
                ids = re.findall(r'https://www.cls.cn/detail/(\d+)', content)
                existing_ids.update(ids)
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        return existing_ids

    @staticmethod
    def _parse_existing_telegrams(file_path):
        """ä»æ–‡ä»¶ä¸­è§£æå·²å­˜åœ¨çš„ç”µæŠ¥å†…å®¹ï¼Œè¿”å›ç”µæŠ¥åˆ—è¡¨"""
        telegrams = []
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç”µæŠ¥æ¡ç›®
                # åŒ¹é…æ ¼å¼ï¼š  1. [00:56] [ã€å°é£é»„è‰²é¢„è­¦ç”Ÿæ•ˆ å¹¿ä¸œæ¹›æ±Ÿå…¨å¸‚åœè¯¾ã€‘è´¢è”ç¤¾6æœˆ13æ—¥ç”µï¼Œ...](https://www.cls.cn/detail/2056133)
                # æˆ–è€…ï¼š      1. [00:56] ã€å°é£é»„è‰²é¢„è­¦ç”Ÿæ•ˆ å¹¿ä¸œæ¹›æ±Ÿå…¨å¸‚åœè¯¾ã€‘è´¢è”ç¤¾6æœˆ13æ—¥ç”µï¼Œ...
                # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾URLæ˜¯å¯é€‰çš„ï¼Œå¹¶ä¸”å†…å®¹å¯èƒ½åŒ…å«æ–¹æ‹¬å·
                # åŒ¹é…æ—¶é—´ã€å†…å®¹å’Œå¯é€‰çš„URLåŠID
                # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ›´å¥å£®åœ°åŒ¹é…æ—¶é—´ã€å†…å®¹å’ŒURL
                # åŒ¹é…æ¨¡å¼ï¼šæ•°å­—. [æ—¶é—´] [å†…å®¹](URL) æˆ– æ•°å­—. [æ—¶é—´] å†…å®¹
                # è€ƒè™‘åˆ°å†…å®¹ä¸­å¯èƒ½åŒ…å«æ–¹æ‹¬å·ï¼Œä½¿ç”¨éè´ªå©ªåŒ¹é…
                # åŒ¹é…é‡è¦ç”µæŠ¥å’Œä¸€èˆ¬ç”µæŠ¥ä¸¤ç§æ ¼å¼
                matches = re.findall(r'\d+\.\s*\[(\d{2}:\d{2})\]\s*(?:\*?\[([^\]]+)\]\((https://www\.cls\.cn/detail/(\d+))\)\*?|\*?([^*]+)\*?)\n\n', content)

                for match in matches:
                    item_time = match[0] # æ—¶é—´
                    # æ ¹æ®åŒ¹é…ç»„åˆ¤æ–­æ˜¯å¸¦URLçš„è¿˜æ˜¯ä¸å¸¦URLçš„
                    if match[1] and match[2] and match[3]: # å¸¦URLçš„æ ¼å¼
                        item_content = match[1]
                        item_url = match[2]
                        item_id = match[3]
                    else: # ä¸å¸¦URLçš„æ ¼å¼
                        item_content = match[4]
                        item_url = ""
                        item_id = ""
                    
                    # å°è¯•ä»URLä¸­æå–timestamp_rawï¼Œå¦‚æœURLä¸å­˜åœ¨åˆ™è·³è¿‡
                    timestamp_raw = None
                    if item_id:
                        try:
                            # å‡è®¾IDå°±æ˜¯timestamp_rawçš„ä¸€éƒ¨åˆ†æˆ–è€…å¯ä»¥ç”¨æ¥ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„timestamp_raw
                            # è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°ç”¨IDä½œä¸ºtimestamp_rawï¼Œæˆ–è€…å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œæ›´å¤æ‚çš„è½¬æ¢
                            # ä¸ºäº†é¿å…é‡å¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å“ˆå¸Œå€¼æˆ–è€…ç›´æ¥ä½¿ç”¨ID
                            timestamp_raw = int(item_id) # å‡è®¾IDå¯ä»¥ç›´æ¥ä½œä¸ºæ—¶é—´æˆ³
                        except ValueError:
                            pass # å¦‚æœIDä¸æ˜¯æ•°å­—ï¼Œåˆ™è·³è¿‡

                    telegrams.append({
                        "id": item_id,
                        "content": item_content,
                        "time": item_time,
                        "url": item_url,
                        "timestamp_raw": timestamp_raw # ç¡®ä¿æœ‰è¿™ä¸ªå­—æ®µ
                    })
            except Exception as e:
                print(f"è§£ææ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        return telegrams

    @staticmethod
    def _build_file_content(date_str, telegrams):
        """æ„å»ºæ–‡ä»¶å†…å®¹"""
        if not telegrams:
            return "" # å¦‚æœæ²¡æœ‰ç”µæŠ¥ï¼Œä¸è¿”å›ä»»ä½•å†…å®¹

        # å…ˆæ˜¾ç¤ºæ ‡çº¢çš„ç”µæŠ¥
        red_telegrams = [t for t in telegrams if t.get("is_red")]
        normal_telegrams = [t for t in telegrams if not t.get("is_red")]

        text_content = ""

        if red_telegrams:
            text_content += "**ğŸ”´ é‡è¦ç”µæŠ¥**\n\n"
            for i, t in enumerate(red_telegrams):
                # æ ¼å¼åŒ–æ—¶é—´ï¼Œä¾‹å¦‚ï¼š[07:00]
                formatted_time = f"[{t.get('time', '')}]"
                # æ„å»ºç”µæŠ¥å†…å®¹ï¼Œå¦‚æœis_redä¸ºTrueï¼Œåˆ™åŠ ç²—
                telegram_content = f"ã€{t.get('title', '')}ã€‘{t.get('content', '')}"
                # æ„å»ºURLéƒ¨åˆ†ï¼Œå¦‚æœå­˜åœ¨
                url_part = f"({t.get('url', '')})" if t.get('url') else ""
                text_content += f"{i+1}. {formatted_time} **[{telegram_content}]{url_part}**\n\n"

        if normal_telegrams:
            if red_telegrams:
                text_content += "\n" # å¦‚æœæœ‰é‡è¦ç”µæŠ¥ï¼ŒåŠ ä¸€ä¸ªç©ºè¡Œåˆ†éš”
            text_content += "**ğŸ“° ä¸€èˆ¬ç”µæŠ¥**\n\n"
            for i, t in enumerate(normal_telegrams):
                # æ ¼å¼åŒ–æ—¶é—´ï¼Œä¾‹å¦‚ï¼š[07:00]
                formatted_time = f"[{t.get('time', '')}]"
                # æ„å»ºç”µæŠ¥å†…å®¹
                telegram_content = f"ã€{t.get('title', '')}ã€‘{t.get('content', '')}"
                # æ„å»ºURLéƒ¨åˆ†ï¼Œå¦‚æœå­˜åœ¨
                url_part = f"({t.get('url', '')})" if t.get('url') else ""
                text_content += f"{i+1}. {formatted_time} [{telegram_content}]{url_part}\n\n"

        return text_content


def main():
    telegrams = CailianpressAPI.fetch_telegrams()
    if not telegrams:
        print("æœªè·å–åˆ°è´¢è”ç¤¾ç”µæŠ¥æˆ–è·å–å¤±è´¥ã€‚")
        return

    # è·å–å½“å¤©å·²ä¿å­˜çš„ç”µæŠ¥IDï¼Œç”¨äºå»é‡
    output_dir = Path(CONFIG["OUTPUT_DIR"])
    today_date = TimeHelper.get_beijing_time().strftime("%Y-%m-%d")
    file_path = output_dir / f"è´¢è”ç¤¾ç”µæŠ¥_{today_date}.md"
    existing_ids = FileWriter._get_existing_telegram_ids(file_path)

    # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„ç”µæŠ¥ï¼Œå¾—åˆ°çœŸæ­£éœ€è¦å¤„ç†çš„æ–°ç”µæŠ¥
    new_telegrams_to_process = [t for t in telegrams if str(t.get("id")) not in existing_ids]

    if not new_telegrams_to_process:
        print("æ²¡æœ‰æ–°çš„è´¢è”ç¤¾ç”µæŠ¥éœ€è¦ä¿å­˜æˆ–å‘é€ã€‚")
        return

    # å¯¹éœ€è¦å¤„ç†çš„æ–°ç”µæŠ¥æŒ‰åŸå§‹æ—¶é—´æˆ³å€’åºæ’åºï¼Œç¡®ä¿é£ä¹¦æ¥æ”¶åˆ°çš„ä¹Ÿæ˜¯æŒ‰æ—¶é—´å€’åºçš„
    new_telegrams_to_process.sort(key=lambda x: int(x.get("timestamp_raw", 0)), reverse=True)

    # ä¿å­˜æ–°çš„ç”µæŠ¥åˆ°æ–‡ä»¶ (FileWriter.save_telegrams_to_file å†…éƒ¨ä¼šæŒ‰æ—¥æœŸå½’æ¡£å’Œå»é‡)
    FileWriter.save_telegrams_to_file(new_telegrams_to_process)

    # å°è¯•å‘é€ Webhook åˆ°é£ä¹¦è‡ªåŠ¨åŒ– (åªå‘é€å½“å¤©æ–°è·å–å¹¶å·²æ’åºçš„ç”µæŠ¥)
    webhook_url = CONFIG["FEISHU_WEBHOOK_URL"]
    if webhook_url:
        try:
            # æ„å»ºå‘é€åˆ°é£ä¹¦ Webhook çš„å†…å®¹
            combined_telegram_content = "\n\n".join([
                f"[{t.get('time', '')}] {t.get('content', '')} - {t.get('url', '')}"
                for t in new_telegrams_to_process
            ])

            payload = {
                "content": {
                    "text": combined_telegram_content,
                    "total_titles": len(new_telegrams_to_process),
                    "timestamp": TimeHelper.format_datetime(),
                    "report_type": "è´¢è”ç¤¾ç”µæŠ¥"
                }
            }
            response = requests.post(webhook_url, json=payload)
            if response.status_code == 200:
                print("æˆåŠŸå‘é€ Webhook åˆ°é£ä¹¦è‡ªåŠ¨åŒ–ã€‚")
            else:
                print(f"å‘é€ Webhook åˆ°é£ä¹¦è‡ªåŠ¨åŒ–å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œå“åº”ï¼š{response.text}")
        except Exception as e:
            print(f"å‘é€ Webhook åˆ°é£ä¹¦è‡ªåŠ¨åŒ–æ—¶å‡ºé”™ï¼š{e}")
    else:
        print("è­¦å‘Š: FEISHU_WEBHOOK_URLæœªè®¾ç½®ï¼Œè·³è¿‡é£ä¹¦è‡ªåŠ¨åŒ– Webhook å‘é€ã€‚")


if __name__ == "__main__":
    main()
